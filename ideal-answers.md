# Case 1: Ideal Answers & Scoring Rubric

## Overview

This document provides guidance for assessing student responses to the Case 1 pre-meeting assignment. Remember: there are no objectively "correct" positions on which option to choose, but there are higher and lower quality analyses.

**Assessment Philosophy**:
- Reward depth of thinking over agreement with instructor views
- Value consideration of multiple perspectives and trade-offs
- Assess the quality of reasoning, not the conclusion reached
- Give credit for original insights and creative problem-solving

---

## Question 1: Stakeholder Analysis & Ethical Framework

### Point Distribution (10 points total)
- Part A - Stakeholder identification and impact: 5 points
- Part B - Ethical framework selection and application: 5 points

### Scoring Breakdown

**Prompt Sophistication (3.5 points)**
- Demonstrates understanding of complex stakeholder relationships
- Recognizes both direct and indirect impacts
- Identifies non-obvious stakeholders or second-order effects

**Ethical Awareness (3.5 points)**
- Shows genuine engagement with ethical principles
- Recognizes moral complexity and competing values
- Applies framework thoughtfully rather than superficially

**Business Acumen (3 points)**
- Realistic about organizational constraints
- Connects ethical considerations to business outcomes
- Understands practical implications of different frameworks

---

### Part A: Exemplary Answer Elements

**Strong responses identify stakeholders such as**:

**Tier 1 (Most Directly Impacted)**:
- Loan applicants (especially in minority communities)
- Current loan officers and staff
- Shareholders/investors

**Tier 2 (Significantly Impacted)**:
- Customers of competing banks (market dynamics shift)
- Community organizations in affected zip codes
- Regulatory agencies (monitoring compliance)

**Tier 3 (Indirectly Impacted)**:
- Future employees (what kind of bank does Liberty become?)
- Vendor ecosystem (other AI providers watching this decision)
- Industry as a whole (precedent-setting)

**Excellent answers will**:
- Identify impacts beyond the obvious (e.g., not just "applicants will be affected" but specifically "Black and Hispanic small business owners seeking growth capital may face higher barriers, potentially slowing economic development in their communities")
- Recognize positive AND negative impacts for same stakeholder group
- Note how impacts differ by which option is chosen

**Example of strong stakeholder analysis**:

> "The three most impacted groups are: (1) **Minority loan applicants**: Currently face 23% auto-decline rate vs. 12% for white applicants under LendSmart™. Negative impact: reduced access to capital, slower business growth. Positive impact: if system is fixed, they gain faster processing and clearer feedback. (2) **Loan officers**: Face potential job displacement or role change. Negative: lose autonomy, relationship-based lending discretion. Positive: freed from tedious data entry, can focus on complex cases. (3) **Liberty Regional's brand/reputation**: Either becomes known as innovator in responsible AI (if done well) or exemplar of algorithmic discrimination (if done poorly). Stakes are existential for a community bank built on trust."

**Weak responses**:
- List stakeholders without explaining specific impacts
- Only identify obvious groups (applicants, employees, shareholders)
- Fail to distinguish positive and negative effects
- Generic statements that could apply to any case

---

### Part B: Exemplary Answer Elements

**Strong responses will**:
- Choose a framework and explain the choice
- Apply the framework specifically to this case
- Acknowledge limitations of the chosen framework
- Possibly note tensions between frameworks

**Acceptable frameworks**: Any of the listed frameworks is fine. What matters is the quality of application.

**Example of strong framework application (Stakeholder Theory)**:

> "I believe stakeholder theory should guide this decision because Liberty Regional Bank's legitimacy depends on balancing competing interests, not optimizing for shareholders alone. Under stakeholder theory, we must ask: Are we treating each group as an end in themselves, or merely as means to profit? The challenge here is that stakeholders have conflicting interests - shareholders want efficiency, minority applicants want fairness, loan officers want autonomy, regulators want compliance. Stakeholder theory forces us to find solutions that don't sacrifice one group entirely for another's benefit - which is why Options 3 or 4 seem most aligned with this framework. The limitation of stakeholder theory here is that it doesn't provide a clear decision rule when stakeholders fundamentally conflict."

**Example of strong framework application (Utilitarian)**:

> "A utilitarian framework asks: which option produces the greatest good for the greatest number? The math initially seems to favor deployment (more customers served faster, significant cost savings, shareholders benefit). But we must also count the harms: discriminatory denials cause real economic pain to minority applicants and their communities. The key utilitarian question is whether the aggregate benefit of efficiency outweighs the concentrated harm of disparate impact. What complicates this is that we don't know the counterfactual - is human lending better or worse for minority applicants? If we're making bias visible rather than creating it, perhaps deployment with monitoring (Option 3) maximizes utility by getting improvements while maintaining benefits."

**Weak responses**:
- Name a framework without explaining it
- Choose framework but don't apply it to the case
- Confuse different ethical theories
- Superficial application ("rights-based means people have rights, so we should protect them")

---

### Grading Guide for Question 1

**9-10 points (Exceptional)**:
- Insightful stakeholder analysis identifying 3+ groups with specific, nuanced impacts
- Sophisticated framework selection with clear rationale
- Thoughtful application showing understanding of ethical complexity
- Recognizes limitations and trade-offs
- Writing is clear and well-organized

**7-8 points (Proficient)**:
- Identifies appropriate stakeholders with reasonable impact analysis
- Chooses framework and applies it to the case
- Shows understanding of ethical dimensions
- Some recognition of trade-offs
- Generally clear writing

**5-6 points (Developing)**:
- Lists stakeholders but impacts are generic or superficial
- Framework chosen but application is weak or confused
- Limited engagement with ethical complexity
- Assertions without reasoning
- Writing may be unclear or disorganized

**3-4 points (Beginning)**:
- Stakeholder analysis is incomplete or misses key groups
- Framework misunderstood or misapplied
- Minimal ethical reasoning
- Largely opinion-based without analysis

**0-2 points (Insufficient)**:
- Does not meaningfully address the question
- Serious misunderstandings of case or concepts
- Extremely brief or off-topic

---

## Question 2: Risk-Benefit Analysis

### Point Distribution (10 points total)
- Part A - Option selection and contrast: 2 points
- Part B - Financial/Risk/Time analysis: 6 points
- Part C - Decision with rationale: 2 points

### Scoring Breakdown

**Prompt Sophistication (3.5 points)**:
- Identifies non-obvious risks and opportunities
- Thinks systematically about second-order effects
- Considers different time horizons thoughtfully

**Ethical Awareness (3.5 points)**:
- Weighs competing values (efficiency vs. fairness)
- Recognizes how different groups experience risk differently
- Considers long-term ethical implications

**Business Acumen (3 points)**:
- Realistic about financial constraints and opportunities
- Understands competitive dynamics
- Practical about implementation challenges

---

### Exemplary Answer Elements

**Part A - Strong option contrasts**:

Examples of meaningful contrasts:
- Option 1 vs. Option 4 (maximum efficiency vs. maximum caution)
- Option 2 vs. Option 3 (technical fix vs. social/PR fix)
- Option 3 vs. Option 5 (embrace AI with guardrails vs. reject AI entirely)

**Example of strong contrast explanation**:

> "I'm comparing Option 1 (deploy as-is) vs. Option 4 (delay 6 months for fixes) because this represents the fundamental tension Liberty Regional faces: urgency vs. responsibility. Option 1 says 'we can't afford to wait, we'll manage risks as they emerge.' Option 4 says 'we can't afford to get this wrong, better to lose money than lose trust.' These aren't just different choices—they represent different philosophies about what kind of bank Liberty Regional wants to be."

---

**Part B - Strong analytical elements**:

**Financial factors beyond the numbers**:
- Opportunity cost of lost customers during delay
- Cost of potential class-action lawsuit (not just regulatory penalty)
- Value of being first-mover vs. fast-follower in AI adoption
- Impact on ability to attract/retain talent (both loan officers and tech talent)
- Insurance cost changes based on AI risk profile
- Access to capital (investors increasingly scrutinize ESG/AI governance)

**Risk factors not fully captured**:
- Reputational risk is hard to quantify but could dwarf financial projections
- Regulatory landscape is changing - today's compliance may be tomorrow's violation
- Vendor lock-in risk (switching costs if FinTech Solutions fails)
- Model drift risk (accuracy degrades over time without monitoring)
- Competitive response (what if rivals launch better AI + fairness marketing?)
- Employee morale and quiet quitting if forcing AI adoption

**Time horizon analysis**:
- **1 year**: Financial returns dominate for Options 1-3, Options 4-5 look expensive
- **3 years**: Reputational and legal risks may materialize; Option 4's upfront cost looks smarter if it avoids lawsuit
- **5 years**: Industry may have moved past this AI generation; early adopters' mistakes become cautionary tales vs. competitive advantages

**Example of strong time horizon thinking**:

> "The relative attractiveness flips over time. In Year 1, Option 1 looks best financially ($1.6M gain). By Year 3, if there's been a discrimination investigation or lawsuit, Option 1 could be the worst choice (millions in legal costs, brand damage). Meanwhile Option 4, which looks expensive in Year 1 (only $600K gain), could be the winner in Year 3-5 if it positions Liberty Regional as the responsible AI bank that competitors copy. The question is: what's our risk tolerance and time horizon? Are we managing for this quarter or this decade?"

---

**Part C - Strong decision rationale**:

**Excellent answers will**:
- Make a clear choice
- Explain the key trade-off accepted
- Show awareness of what's being sacrificed
- Connect to earlier analysis

**Example**:

> "Between Options 1 and 4, I choose Option 4 (delay 6 months). Here's why: Liberty Regional is a community bank whose competitive advantage is trust and relationships—exactly what Option 1 puts at risk. The $600K opportunity cost is real but manageable. What's not manageable is a discrimination scandal for a bank built on community connections. Option 4 gives us time to get independent validation, engage affected communities, and deploy responsibly. Yes, we fall further behind competitors, but we differentiate by being the bank that does AI right. In 3-5 years, that differentiation could be worth more than the short-term savings of Option 1."

---

### Grading Guide for Question 2

**9-10 points (Exceptional)**:
- Identifies meaningful option contrast with clear reasoning
- Sophisticated analysis of financial, risk, and time factors
- Identifies non-obvious considerations
- Time horizon analysis shows strategic thinking
- Clear decision with strong rationale
- Excellent integration of prior analysis

**7-8 points (Proficient)**:
- Reasonable option contrast
- Solid analysis of multiple factors
- Some consideration of time horizons
- Clear decision with adequate rationale
- Good connection to prior analysis

**5-6 points (Developing)**:
- Option contrast somewhat superficial
- Limited analysis beyond case data
- Minimal time horizon thinking
- Decision stated but reasoning weak
- Some gaps in logic or analysis

**3-4 points (Beginning)**:
- Poor option selection or weak contrast
- Analysis largely repeats case information
- No time horizon consideration
- Unclear or poorly justified decision

**0-2 points (Insufficient)**:
- Does not meaningfully address the question
- Serious misunderstandings
- Extremely brief or off-topic

---

## Question 3: AI-Assisted Decision Making

### Point Distribution (10 points total)
- Quality of prompts (2-3 prompts): 7 points
- Purpose explanations: 3 points

### Scoring Breakdown

**Prompt Sophistication (3.5 points)**:
- Prompts ask for actionable, specific information
- Demonstrates understanding of AI capabilities and limitations
- Shows strategic thinking about what AI can/can't help with

**Ethical Awareness (3.5 points)**:
- Prompts seek to understand stakeholder perspectives
- Asks AI to surface ethical considerations or blind spots
- Uses AI to challenge assumptions, not just confirm them

**Business Acumen (3 points)**:
- Prompts are practical and relevant to real decision-making
- Seeks information that would actually influence the vote
- Realistic about what AI can provide vs. what requires human judgment

---

### Exemplary Prompts

**Example 1: Legal/Regulatory Context**

**PROMPT**:
> "I'm analyzing a case where a regional bank is considering deploying an AI loan screening system that shows disparate impact by race (23% auto-decline rate for Black applicants vs. 12% for white applicants), even though race is not used as an input variable. The AI uses zip codes, employment type, and credit history as inputs. What are the key legal considerations under ECOA and disparate impact doctrine? Specifically: (1) Can a lender be liable even if they don't use protected characteristics as direct inputs? (2) What does 'business necessity' mean as a defense? (3) What recent enforcement actions or case law should I know about for AI in lending? Please provide 2-3 specific precedents or regulatory guidance documents if possible."

**PURPOSE**:
> "I need to understand the legal risk more precisely. The case says there's a 15-25% chance of investigation but I don't know if that's realistic. I also want to know what 'business necessity' means as a legal defense—can we argue the efficiency gains justify the disparate impact? Understanding actual precedents will help me assess whether the legal risk is theoretical or serious."

**Why this is strong**:
- Specific to the case details
- Asks for actionable legal framework
- Requests concrete precedents, not just general information
- Shows student doesn't just want AI to make the decision but to inform it
- Purpose clearly connects to a gap in understanding

---

**Example 2: Challenging Assumptions**

**PROMPT**:
> "I'm leaning toward voting to delay deployment of an AI system for 6 months to fix bias issues, even though it costs the company $600K in lost opportunity. Challenge this position: What are the strongest arguments someone could make for deploying the AI system now rather than waiting? What assumptions am I making that might be wrong? For instance, am I overestimating the reputational risk, underestimating competitive pressure, or incorrectly assuming that delaying will actually result in a better system? Try to make the case against my position as strongly as possible."

**PURPOSE**:
> "I want to stress-test my thinking and make sure I'm not falling into confirmation bias. If I walk into the board meeting only thinking about why I'm right, I won't be prepared for counterarguments. I need the AI to play devil's advocate and surface considerations I'm overlooking."

**Why this is strong**:
- Uses AI to challenge, not confirm, existing thinking
- Shows metacognitive awareness (worried about confirmation bias)
- Specific about what kind of challenge is needed
- Demonstrates intellectual humility

---

**Example 3: Stakeholder Perspective**

**PROMPT**:
> "Imagine you are a loan officer who has worked at Liberty Regional Bank for 15 years, primarily serving small businesses in Hartford's minority communities. You've built deep relationships with clients and often advocate for applicants who look risky on paper but whom you know personally. The bank is about to deploy an AI screening system that would reduce your discretion and potentially auto-decline many of your clients. How would you feel about this change? What concerns would you raise with the board? What would you need from the bank to feel okay about this transition? Give me 3-4 specific concerns and 2-3 specific requests you'd make."

**PURPOSE**:
> "The case gives us the VP of HR's position, but I want to understand what frontline loan officers would actually feel and fear. This helps me think about Option 5 (reject AI and invest in training) more seriously, and also helps me think about what guardrails would be necessary if we do deploy. Understanding employee perspective is crucial since high turnover could cost more than the AI saves."

**Why this is strong**:
- Role-playing prompt to access perspective not fully developed in case
- Specific about what information is needed
- Clear connection to decision-making (helps evaluate Option 5)
- Shows empathy and stakeholder thinking

---

**Example 4: Alternative Solutions**

**PROMPT**:
> "The case presents 5 options for how Liberty Regional Bank should proceed with its AI loan screening system. Are there other options not listed that could address both the efficiency goals (40% faster processing, $1.2M savings) and the fairness concerns (disparate impact on minority applicants)? Think creatively about hybrid approaches, phased rollouts, different uses of the same technology, or entirely different solutions to the underlying problem. Give me 2-3 alternatives with a brief pro/con for each."

**PURPOSE**:
> "I'm worried that the five options in the case create a false choice. Maybe there's a sixth option that's better than all of them. I want to use AI to think outside the box before I lock into one of the presented options. If I bring a creative alternative to the board meeting, it could shift the whole conversation."

**Why this is strong**:
- Uses AI for creative problem-solving
- Doesn't accept framing as given
- Requests structured output (pros/cons)
- Shows strategic thinking about board dynamics

---

### Weak Prompts (Examples to Avoid)

**Weak Example 1**:
> "What should Liberty Regional Bank do about the AI lending system?"

**Why it's weak**:
- Too vague
- Asks AI to make the decision
- No specificity about what information is needed
- Shows student isn't engaging with the case

---

**Weak Example 2**:
> "Summarize the Liberty Regional Bank case."

**Why it's weak**:
- Student should have already read and understood the case
- Doesn't help with decision-making
- No clear learning objective

---

**Weak Example 3**:
> "Is it ethical to use AI in lending?"

**Why it's weak**:
- Too general (not specific to this case)
- Philosophical question unlikely to yield actionable insight
- Doesn't show engagement with case specifics

---

### Grading Guide for Question 3

**9-10 points (Exceptional)**:
- 2-3 sophisticated, specific prompts
- Prompts show strategic thinking about what AI can help with
- Clear purposes that connect to decision-making needs
- Evidence of using AI to challenge thinking, not just confirm it
- Prompts are actionable and would likely yield useful responses

**7-8 points (Proficient)**:
- 2-3 reasonable prompts with clear purposes
- Prompts are specific to the case
- Some strategic thinking about AI usage
- Purposes explain what student hopes to learn
- Prompts would likely be helpful

**5-6 points (Developing)**:
- 2 prompts that are somewhat vague or generic
- Limited connection to specific decision-making needs
- Purposes are present but superficial
- Prompts might not yield actionable insights

**3-4 points (Beginning)**:
- 1-2 weak or very general prompts
- Purposes unclear or missing
- Prompts ask AI to make decision rather than inform it
- Little evidence of strategic thinking

**0-2 points (Insufficient)**:
- Prompts missing or completely off-topic
- No purposes provided
- Serious misunderstanding of the task

---

## Question 4: Your Position & Advocacy Strategy

### Point Distribution (10 points total)
- Part A - Clear vote: 1 point
- Part B - Core argument: 5 points
- Part C - Anticipating opposition: 4 points

### Scoring Breakdown

**Prompt Sophistication (3.5 points)**:
- Argument is well-structured and persuasive
- Shows strategic thinking about advocacy
- Anticipates objections thoughtfully

**Ethical Awareness (3.5 points)**:
- Acknowledges trade-offs honestly
- Appeals to ethical principles without being preachy
- Shows respect for other viewpoints

**Business Acumen (3 points)**:
- Argument is realistic and practical
- Understands organizational context
- Makes business case alongside ethical case

---

### Exemplary Answer Elements

**Part B - Strong Core Arguments**:

**Example 1: Arguing for Option 4 (Delay)**

> "I vote for Option 4: delay 6 months for independent audit and fixes. Here's why this is the right choice for Liberty Regional. First, our competitive advantage is community trust—we're not Wells Fargo, we're the local bank that knows your name. One discrimination scandal destroys that forever, and the $600K opportunity cost is insurance against existential risk. Second, the case reveals we've never audited our human loan officers for bias—we're operating blind. Six months lets us establish a baseline, fix the AI properly, and deploy with confidence rather than crossing our fingers. Third, we can turn the delay into competitive advantage: market ourselves as 'the bank that does AI right' while competitors rush ahead and stumble. The efficiency gains aren't going anywhere—LendSmart™ will still work in six months—but our reputation, once damaged, can't be rebuilt. I'm voting for sustainable advantage over short-term gains."

**Why this is strong**:
- Leads with compelling reason (competitive advantage is trust)
- Acknowledges trade-off ($600K opportunity cost)
- Makes both business and ethical case
- Specific to Liberty Regional's context
- Confident without being dismissive of other views

---

**Example 2: Arguing for Option 3 (Deploy + Community Investment)**

> "I vote for Option 3: deploy with monitoring and community investment. This is the only option that actually solves both problems. We get the efficiency gains we desperately need ($1.1M after community program costs) while proactively addressing fairness concerns. Here's what competitors aren't doing: being transparent about how AI works and helping communities succeed with it. The $500K financial literacy program isn't charity—it's customer acquisition in underserved markets and reputation insurance. We deploy with strict monitoring, human override capability, and a kill switch if disparities worsen. But we also get ahead of the narrative: Liberty Regional becomes the case study for responsible AI banking. Yes, there's risk, but Options 4 and 5 guarantee we fall further behind while our problems don't go away. Option 3 threads the needle: business necessity with social responsibility."

**Why this is strong**:
- Makes affirmative case (not just defense)
- Reframes community investment as strategic, not just ethical
- Specific about implementation (monitoring, kill switch)
- Acknowledges risk while arguing it's manageable
- Positions Liberty Regional uniquely

---

**Part C - Strong Objection Anticipation**:

**Example** (for someone voting Option 4 - Delay):

> **Objection 1**: "We can't afford to wait—we're losing $100K per month in opportunity cost while competitors pull ahead."
>
> **Rebuttal**: "I understand the urgency, but this framing assumes deployment goes smoothly. If we deploy as-is and face an investigation or lawsuit in month 3, we haven't saved $600K—we've lost millions. The real question isn't 'can we afford to wait' but 'can we afford to get this wrong?' Six months of lost opportunity is the price of doing it right. Plus, we can use that time to market our caution as a differentiator."
>
> **Objection 2**: "Six months won't actually fix anything—we'll just delay the same decision."
>
> **Rebuttal**: "Valid concern. That's why I'd make the delay conditional: we commit now that if independent audit shows we can't achieve fairness within risk tolerance, we reject AI entirely (Option 5). But if audit shows a path forward, we deploy with confidence. The delay isn't procrastination—it's gathering the information we need to make this decision properly. Right now we're guessing; in six months we'd know."

**Why this is strong**:
- States objections clearly and fairly
- Rebuttals engage the substance, don't dodge
- Shows student has thought through counterarguments
- Demonstrates intellectual honesty (acknowledges validity of concerns)

---

### Grading Guide for Question 4

**9-10 points (Exceptional)**:
- Clear vote stated
- Core argument is persuasive, well-structured, and compelling
- Appeals to both business and ethical considerations
- Acknowledges trade-offs honestly
- Two strong objections anticipated
- Rebuttals engage substance thoughtfully
- Shows strategic thinking about advocacy

**7-8 points (Proficient)**:
- Vote clearly stated
- Solid core argument with reasonable support
- Some acknowledgment of trade-offs
- Two objections identified
- Rebuttals address the objections
- Generally persuasive

**5-6 points (Developing)**:
- Vote stated
- Core argument present but underdeveloped
- Limited acknowledgment of trade-offs
- Objections weak or rebuttals superficial
- Some persuasive elements but gaps in logic

**3-4 points (Beginning)**:
- Vote may be unclear
- Weak or very brief argument
- No real acknowledgment of trade-offs
- Poor objection anticipation
- Minimal persuasive quality

**0-2 points (Insufficient)**:
- Question not meaningfully addressed
- Extremely brief or off-topic

---

## Overall Assignment Grading

### Total Points: 40 (sum of all four questions)

### Letter Grade Conversion
- 37-40 points: A (93-100%)
- 35-36 points: A- (88-92%)
- 33-34 points: B+ (83-87%)
- 31-32 points: B (80-82%)
- 29-30 points: B- (73-79%)
- 27-28 points: C+ (70-72%)
- 24-26 points: C (60-69%)
- 20-23 points: D (50-59%)
- Below 20: F (below 50%)

---

## Grading Efficiency Tips

With 17 students, you'll have 17 × 4 questions = 68 individual question responses to grade.

**Time-Saving Strategies**:

1. **Use the rubric ruthlessly**: Don't agonize over 7 vs. 8 points. If it's clearly proficient, give 7-8. Move on.

2. **Grade by question, not by student**: Grade all Question 1's, then all Question 2's. You'll get faster as you see patterns.

3. **Create comment bank**: Save 5-10 standard comments for each question that you can copy/paste:
   - "Strong stakeholder analysis with specific impacts"
   - "Framework chosen but application could be deeper"
   - "Excellent prompt - specific and actionable"
   - "Consider how this plays out over different time horizons"

4. **Focus feedback on Question 3 (prompts)**: This is where students need most skill development. Questions 1, 2, 4 are more about synthesis.

5. **Batch grading**: Set timer for 90 minutes, grade as many as you can. Return to difficult cases at end.

6. **Target 5-7 minutes per student** (85-119 minutes total per case, ~340-476 minutes across all 4 cases)

---

## Common Student Mistakes to Watch For

1. **Prompt Quality Issues**:
   - Asking AI to make the decision ("What should I do?")
   - Prompts that are too vague to be useful
   - Asking for information already in the case
   - Not explaining purpose of prompts

2. **Analysis Issues**:
   - Stating position without reasoning
   - Ignoring trade-offs
   - Oversimplifying complexity
   - Failing to consider stakeholders beyond shareholders

3. **Ethical Reasoning Issues**:
   - Treating ethics as separate from business (not integrated)
   - Superficial application of ethical frameworks
   - Assuming there's one "right" answer
   - Dismissing concerns as impractical

4. **Writing Issues**:
   - Way over or under word counts
   - Disorganized responses
   - Not answering all parts of questions
   - Excessive jargon or business-speak

---

## Feedback Themes to Emphasize

Regardless of which option students vote for, emphasize in feedback:

- **Trade-off recognition**: "You clearly recognized the tension between X and Y"
- **Stakeholder thinking**: "Good job considering impact on multiple groups"
- **Prompt sophistication**: "Your prompts show strategic thinking about AI collaboration"
- **Intellectual humility**: "I appreciate that you acknowledged uncertainty"
- **Business + Ethics integration**: "You made both the business and ethical case"

---

*This rubric is designed to assess thinking quality, not position advocacy. Students should feel safe taking any position as long as it's well-reasoned.*
