# Case 1: Ethics Tribunal - Stakeholder Role-Play

## Overview

The Ethics Tribunal is a formal role-play exercise where students embody different stakeholder perspectives to analyze Liberty Regional Bank's AI lending decision and its consequences.

**Timing**: Session 2 (60 minutes)
**Format**: Formal presentations followed by open deliberation
**Purpose**: 
- Develop stakeholder empathy
- Practice arguing from positions students may not personally hold
- Deepen understanding of AI ethics complexities
- Connect Case 1 lessons to broader themes

---

## Session 2 Structure (60 minutes)

### Part 1: Role Selection & Preparation (15 minutes)

**Before Session 2**:
- Post role descriptions on Blackboard
- Ask students to select roles (first-come, first-served)
- If multiple students select same role, they must coordinate
- Provide 5-minute prep time at start of session

**During Prep Time**:
- Students review their role description
- Formulate 2-3 key arguments from that perspective
- Prepare opening statement (1-2 minutes)

---

### Part 2: Tribunal Presentations (30 minutes)

**Format**: Each stakeholder group presents their perspective on what happened and what should have been done.

**Speaking Order** (2 minutes each):
1. Affected Loan Applicant Representative
2. Liberty Regional Loan Officer
3. Shareholder/Investor Representative
4. Consumer Protection Advocate
5. Liberty Regional Board Member (Dissenting)
6. AI Ethics Researcher
7. Community Banking Consultant
8. Federal Banking Regulator

**Presentation Guidelines**:
- State your role and interests clearly
- Explain how Liberty's decision affected you/your constituency
- Argue what the bank should have done differently (if anything)
- Address the consequences that actually occurred
- Be authentic to the role, even if it conflicts with personal views

---

### Part 3: Open Deliberation (15 minutes)

**Facilitated Discussion Questions**:
1. Which stakeholder bore the greatest harm from this decision?
2. Which stakeholder had the most legitimate claim on the board's attention?
3. Were some stakeholder interests fundamentally irreconcilable?
4. What would a fair resolution look like now that consequences have occurred?
5. What systemic changes would prevent this dilemma in the future?

**Instructor Role**:
- Ensure all perspectives are heard
- Highlight tensions between stakeholders
- Push students to defend positions they might not personally hold
- Connect to broader course themes

---

## Stakeholder Roles (8 roles for 17 students)

Students may select roles individually or in pairs (depending on interest). If multiple students select the same role and disagree on the position, their perspectives nullify each other (abstention in final deliberation).

---

### Role 1: Affected Loan Applicant Representative

**Who You Are**:
You are Marcus Thompson, a 42-year-old Black small business owner who applied for a $75,000 loan to expand your successful Hartford barbershop into a second location. You were auto-declined by LendSmart™ despite:
- 12 years in business with consistent profitability
- Credit score of 680 (not excellent, but solid)
- Strong business plan with market research
- Existing relationship with Liberty Regional (personal and business accounts for 8 years)

**What Happened to You**:
- Auto-declined within 48 hours with generic explanation
- Requested human review, was told AI decision stands unless you provide additional documentation
- Additional documentation required was extensive and time-consuming
- By the time you got approved (4 months later), the commercial space was rented to someone else
- You eventually got a loan from a credit union, but lost the opportunity

**Your Perspective**:
You feel betrayed by a bank you trusted and supported. The AI treated you like a risk score, not a person with a track record. You suspect that if you were white, the AI would have treated you differently—or at least a human loan officer would have vouched for you.

**Your Argument**:
- Liberty Regional prioritized efficiency over fairness and relationships
- The bank has a responsibility to its community, not just its shareholders
- AI should assist loan officers, not replace their judgment
- You're not against AI, but it should be explainable and accountable
- Liberty should compensate affected applicants and commit to fixing the system

**Questions You'll Raise**:
- Why should I bear the cost of Liberty Regional's technology experiment?
- How many others like me were denied opportunities?
- What's the bank doing to make this right?
- Can I ever trust Liberty Regional again?

---

### Role 2: Liberty Regional Loan Officer

**Who You Are**:
You are Jennifer Rodriguez, a 15-year veteran loan officer at Liberty Regional. You've built your career on relationship-based lending—knowing your clients' businesses, their communities, and their character beyond what appears on a credit report.

**What Happened to You**:
- LendSmart™ was deployed over your objections
- You were told to "trust the AI" and only review flagged applications
- Several of your long-time clients were auto-declined despite your knowledge they were good risks
- You tried to override the AI but were told the system must be followed
- Six of your colleagues quit in protest; you've considered it
- Your role has been reduced to data entry and explaining AI decisions you don't agree with

**Your Perspective**:
Banks are about relationships, not algorithms. AI can't assess character, community ties, or business acumen. Liberty Regional is throwing away its competitive advantage (personalized service) to imitate fintech companies it can never out-compete on technology.

**Your Argument**:
- AI should assist, not replace, experienced loan officers
- The bank devalued institutional knowledge and relationship capital
- Employee morale and retention matter—losing experienced staff costs more than AI saves
- Community banking requires community knowledge that AI doesn't have
- Liberty should return to human-centered lending with AI as a tool, not a decision-maker

**Questions You'll Raise**:
- Why didn't the board consult the people who actually understand lending?
- How do we rebuild trust with clients we wrongly declined?
- What's my role if an algorithm makes all the decisions?
- Can Liberty compete on technology, or should we compete on service?

---

### Role 3: Shareholder/Investor Representative

**Who You Are**:
You represent the Hartford Pension Fund, which owns 8% of Liberty Regional Bank's stock. You're responsible for maximizing returns for retirees and public employees.

**What Actually Happened** (depends on consequence scenario):
[Adapt based on which consequence was revealed]

**Your Core Perspective**:
The board has a fiduciary duty to shareholders. While ethical concerns matter, the bank's primary obligation is financial performance and shareholder value.

**Your Argument** (if Option 1/3 was chosen and succeeded):
- The board made the right call—efficiency gains are real and necessary
- Competitive pressure required AI adoption
- Delays would have cost shareholder value
- Legal and reputational risks can be managed
- The bank should continue deploying AI to stay competitive

**Your Argument** (if Option 1/3 failed with scandal):
- The board failed to properly assess risks
- Rushing deployment without adequate governance was reckless
- Short-term thinking destroyed long-term value
- Board should be held accountable for poor risk management
- Better to delay and do it right than face existential threats

**Your Argument** (if Option 4/5 was chosen):
- Excessive caution has cost shareholders hundreds of thousands in lost opportunity
- While risk management matters, the board was too conservative
- Competitors are gaining market share
- The bank needs to balance ethics and competitiveness
- Some risk-taking is necessary for growth

**Questions You'll Raise**:
- What is the board's primary obligation—shareholders or other stakeholders?
- How do we compete if we're always slower than rivals?
- What's the acceptable level of risk for returns?
- Should ethics ever override fiduciary duty?

---

### Role 4: Consumer Protection Advocate

**Who You Are**:
You work for the Connecticut Fair Lending Coalition, a nonprofit that advocates for equitable access to credit. You've been monitoring AI lending practices across the state.

**What You Observed**:
Liberty Regional's case is part of a disturbing pattern of AI systems perpetuating historical discrimination in lending. You've documented similar issues at multiple banks.

**Your Perspective**:
AI is being deployed without adequate safeguards, oversight, or accountability. Banks are automating discrimination while hiding behind "objective" algorithms. This is algorithmic redlining and it's illegal and immoral.

**Your Argument**:
- Banks should not deploy AI that shows disparate impact
- "Business necessity" doesn't justify discrimination
- Transparency and explainability should be mandatory
- Affected communities should have input before deployment
- Regulators need to enforce fair lending laws more aggressively
- Liberty Regional should face consequences and be required to fix the system

**Questions You'll Raise**:
- Why should minority communities bear the cost of AI efficiency?
- How is this different from historical redlining?
- What accountability exists when algorithms discriminate?
- Should AI in high-stakes decisions be allowed without explanation?
- What remedies should affected applicants receive?

---

### Role 5: Liberty Regional Board Member (Dissenting)

**Who You Are**:
You were on the Liberty Regional board and voted against the majority decision (whichever option won). You're now watching the consequences unfold.

**Your Perspective** (if you voted for caution and board chose speed):
You warned about rushing into AI deployment. You argued for delay, audit, or rejection. Now you're saying "I told you so"—but you're also trying to figure out how to fix this.

**Your Perspective** (if you voted for speed and board chose caution):
You warned about competitive threats and opportunity costs. You argued for deployment with monitoring. Now you're watching competitors gain ground and you're frustrated.

**Your Argument**:
- The board didn't adequately weigh the trade-offs you identified
- Your concerns have been validated by events
- The board needs better decision-making processes for emerging technology
- Going forward, Liberty needs clearer AI governance frameworks
- [Specific recommendations based on what you advocated for]

**Questions You'll Raise**:
- What can we learn from this mistake?
- How should boards make decisions under uncertainty?
- What governance structures would have led to a better outcome?
- Should dissenting board members be vindicated or accept collective responsibility?

---

### Role 6: AI Ethics Researcher

**Who You Are**:
You're a professor at Yale studying algorithmic fairness in high-stakes decision systems. You've been following the Liberty Regional case as a real-world example.

**Your Perspective**:
This case illustrates fundamental challenges in AI ethics: fairness metrics, competing values, technical limitations, and organizational responsibility.

**Your Key Points**:
1. **Fairness is Multi-Dimensional**: Different fairness metrics can conflict (equal opportunity vs. equal outcomes vs. equal treatment)
2. **Technical Limits**: Current AI can't fully eliminate bias when training data reflects historical discrimination
3. **Transparency Trade-offs**: More explainable AI is often less accurate
4. **Governance Gaps**: Most organizations lack frameworks for responsible AI deployment
5. **Systemic Issues**: Individual bank decisions can't solve structural inequality

**Your Argument**:
Liberty Regional's decision reflects broader challenges the entire industry faces. There are no easy answers, but there are better and worse processes. Responsible AI requires:
- Independent audits before deployment
- Ongoing monitoring and accountability
- Stakeholder engagement
- Willingness to delay or reject if fairness can't be achieved
- Investment in addressing root causes (credit access, financial literacy)

**Questions You'll Raise**:
- What counts as "fair enough" in AI systems?
- Who should decide what trade-offs are acceptable?
- Can AI ever be fair if society is unfair?
- What responsibility do vendors have vs. deploying organizations?

---

### Role 7: Community Banking Consultant

**Who You Are**:
You advise small and mid-size banks on strategy, technology, and competition. You've helped dozens of community banks navigate the AI adoption question.

**Your Perspective**:
Community banks face a genuine dilemma: They can't out-technology the megabanks or fintech companies, but they can't ignore technology either. The question is how to adopt AI in ways that enhance rather than undermine their competitive advantages.

**Your Observations**:
- Banks that rushed into AI without preparation often face problems (Liberty is not unique)
- Banks that rejected AI entirely are losing market share, especially younger customers
- The most successful approaches combine AI efficiency with human relationship management
- Community banks' advantage is local knowledge and personalized service—AI should support that, not replace it

**Your Argument**:
Liberty Regional needed AI, but the implementation approach was flawed. Better strategy would have been:
- Phased rollout starting with low-risk applications
- AI assists loan officers, doesn't replace them
- Extensive testing and monitoring before full deployment
- Marketing the human + AI combination as "best of both worlds"
- Investment in technology and people simultaneously

**Questions You'll Raise**:
- Can community banks compete without AI?
- Can community banks compete with AI if they deploy it poorly?
- What's the right balance between efficiency and relationship banking?
- How should small banks approach technology adoption differently than large banks?

---

### Role 8: Federal Banking Regulator

**Who You Are**:
You work for the Consumer Financial Protection Bureau (CFPB) in the fair lending division. Your job is to ensure banks comply with equal credit opportunity laws.

**Your Perspective**:
AI in lending is inevitable and not inherently problematic—but it must comply with existing laws. Banks are responsible for their algorithms' decisions just as they're responsible for human decisions.

**What the Law Says**:
- Equal Credit Opportunity Act prohibits discrimination based on race, color, religion, national origin, sex, marital status, age
- Disparate impact doctrine: Banks can be liable even without intent to discriminate if practices have discriminatory effects
- Banks using AI must be able to explain decisions and demonstrate business necessity
- Banks must monitor for bias and take corrective action

**Your Argument**:
Liberty Regional (like many banks) treated AI deployment as a technology decision when it's also a compliance and civil rights issue. Proper approach requires:
- Pre-deployment fairness testing
- Ongoing disparate impact monitoring
- Ability to explain individual decisions
- Human review and override capability
- Clear accountability and governance
- Corrective action when disparities are found

**Your Stance** (depends on what happened):
- If Liberty deployed without adequate safeguards: Investigation warranted
- If Liberty delayed for proper audit: Commendable and should be industry standard
- If Liberty rejected AI entirely: Acceptable but not required

**Questions You'll Raise**:
- What does "good faith effort" mean for AI fairness?
- Should AI systems be pre-certified before deployment?
- Who is accountable when algorithms discriminate—bank, vendor, both?
- Should regulations require explainable AI in high-stakes decisions?

---

## Facilitator Guide

### Setting the Stage

**Opening (2 minutes)**:
"Today we're examining Liberty Regional's decision from multiple stakeholder perspectives. Each role represents legitimate interests and concerns. There are no 'villains'—only different values, priorities, and information. Your job is to authentically represent your assigned perspective, even if it conflicts with your personal views. Let's see what we learn when we walk in others' shoes."

---

### Managing the Presentations (30 minutes)

**Keep time strictly**: Each speaker gets 2 minutes. Use a timer visible to all.

**Encourage authenticity**: Students should speak in first person, from the role's perspective.

**No interruptions during presentations**: Save questions and challenges for deliberation.

**Track themes**: Note common concerns and fundamental disagreements for deliberation phase.

---

### Guiding the Deliberation (15 minutes)

**Facilitation Techniques**:

1. **Surface Tensions**: "I heard the shareholder say X, but the loan applicant said Y. How do we reconcile these?"

2. **Push Beyond Positions**: "You said the bank should have delayed. But what if that meant job losses or even failure? Would you still hold that position?"

3. **Test Principles**: "Several of you mentioned fairness. But you seem to define it differently. Can we have multiple definitions of fairness?"

4. **Connect to Cases**: "How would your perspective change if we're talking about AI in healthcare instead of lending? Are the principles the same?"

5. **Look Forward**: "Okay, Liberty made mistakes. What should happen now? What would make affected parties whole?"

---

### Closing Synthesis (5 minutes)

**Key Takeaways to Emphasize**:

1. **Legitimate Pluralism**: Different stakeholders have legitimate but competing interests. AI ethics isn't about finding the "right" answer but navigating trade-offs.

2. **Context Matters**: What's ethical depends on context—bank's size, competitive position, community relationships, risk tolerance.

3. **Process Matters**: Even when outcomes are uncertain, good processes (stakeholder engagement, independent audit, monitoring) matter.

4. **No Perfect Solutions**: Sometimes all options have significant downsides. Maturity means accepting this, not searching for the perfect solution.

5. **Learning from Consequences**: The goal isn't to avoid all mistakes but to learn from them and build better systems.

**Bridge to Next Cases**:
"We'll face similar dilemmas in different contexts throughout this course. The specific stakeholders change, but the underlying tensions—efficiency vs. fairness, innovation vs. caution, individual vs. collective good—recur. Let's carry these insights forward."

---

## Assessment

**Participation Credit** (10 points total for tribunal participation):

- Selected and prepared role: 2 points
- Authentic representation during presentation: 4 points
- Engaged participation in deliberation: 4 points

**No "right answers"**: Points awarded for authentic engagement, not for particular positions.

---

## Adaptations Based on Consequence

### If Consequence Was Negative (Scandal, Failure)

**Tribunal Focus**: What should Liberty do now? Who deserves compensation? How to rebuild trust?

**Additional Questions**:
- Should board members resign?
- What remedies are owed to affected applicants?
- Can trust be restored, or is damage permanent?

---

### If Consequence Was Positive (Success)

**Tribunal Focus**: Does a good outcome justify the approach? What about those still harmed?

**Additional Questions**:
- If most benefited but some were harmed, is that acceptable?
- Does success prove the decision was right, or did Liberty "get lucky"?
- What responsibility exists to the minority who were disadvantaged?

---

### If Consequence Was Mixed

**Tribunal Focus**: How do we weigh competing goods and harms?

**Additional Questions**:
- Which stakeholder outcomes matter most?
- How do we measure success when results are mixed?
- What would have been a "better" outcome and was it achievable?

---

## Tips for Students

**Preparing Your Role**:
1. Read the consequence scenario from your role's perspective
2. Ask: How did this affect me/my constituency?
3. Consider: What would I have wanted the bank to do?
4. Prepare: 2-3 key points you want to make
5. Practice: Your 2-minute opening in role

**During Deliberation**:
- Stay in character (speak as your role, not as yourself)
- Listen for tensions between your interests and others
- Be willing to defend positions you might not personally hold
- Look for potential compromises that serve multiple stakeholders
- Acknowledge when your perspective has blind spots

**After Tribunal**:
- Reflect: What did you learn by arguing from a position different from your own?
- Consider: Which stakeholder perspective was hardest to understand? Why?
- Synthesize: What would you do differently in Liberty's position now?

---

*The Ethics Tribunal is designed to build empathy and reveal the complexity of AI ethics. There are no points for "winning" the debate—only for authentic engagement with perspectives different from your own.*
