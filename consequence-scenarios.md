# Case 1: Consequence Scenarios

## How Consequences Work

Based on the Board's collective vote, Liberty Regional Bank will experience ONE of the following consequence scenarios. The scenario revealed will depend on:

1. **Which option received majority vote** (simple majority)
2. **A stochastic element** - even "good" decisions can have bad outcomes, and vice versa
3. **How convincing the deliberation was** - instructor may choose variant based on quality of discussion

**Important**: These consequences are revealed either:
- Via email 24 hours after the board meeting, OR
- At the start of Session 2

Students should reflect on consequences in a brief post-meeting Blackboard assignment.

---

## Decision Outcome Matrix

### If Board Votes: Option 1 (Deploy As-Is)

**Scenario 1A: "The Fast Track to Trouble" (60% probability)**

**What Happened - Quarter 1**:

Liberty Regional deployed LendSmart™ in early January. Initial results were promising:
- Loan processing time dropped from 14 days to 6 days
- Operating costs decreased by 26%
- Customer satisfaction among approved applicants increased
- Stock price rose 3% on announcement

**What Happened - Quarter 2**:

In mid-March, a Hartford Courant investigative journalist obtained Liberty Regional's loan approval data through a public records request under fair lending disclosure requirements. 

**Front Page Story (March 18)**:
*"Community Bank's AI Denies Black Applicants at Double the Rate of White Applicants"*

The article included interviews with three denied Black small business owners who had strong business plans but were auto-declined by LendSmart™. One owned a barbershop and said: "I've banked with Liberty for 15 years. I thought they knew me. Now I'm just a number to an algorithm."

**What Happened - Quarter 3**:

- **Legal**: Connecticut Attorney General opened investigation
- **Regulatory**: CFPB (Consumer Financial Protection Bureau) requested full documentation
- **Class Action**: Law firm filed class-action lawsuit on behalf of minority applicants
- **Employee**: 6 senior loan officers resigned, citing ethical concerns
- **Customer**: 12% of existing business customers moved to competitors
- **Media**: Regional and national coverage framed Liberty as "algorithmic redlining" example

**Financial Impact (9 months)**:
- Legal costs: $850K (and rising)
- Lost business (customer attrition): $1.2M in annual revenue
- Loan officer replacement costs: $420K
- Stock price decline: -18%
- **Net impact**: -$2.47M

**Additional Consequences**:
- FinTech Solutions Inc. offered to retrain model for free to limit liability
- Board facing shareholder pressure to replace CEO
- Community activists organizing "Bank Local Responsibly" campaign
- Two board members facing calls to resign
- Liberty Regional removed from Connecticut's state government preferred vendor list

**Ethical Toll**:
An estimated 127 minority-owned small businesses were denied loans they would have received under human review. Some closed or laid off employees. Community trust in Liberty Regional Bank severely damaged.

**Your Reflection Assignment**: 
Given this outcome, what would you have done differently? What signals did the board miss? How should Liberty Regional respond now?

---

**Scenario 1B: "Lucky Break... For Now" (25% probability)**

**What Happened - Quarter 1-3**:

Liberty Regional deployed LendSmart™ and experienced the projected efficiency gains without major incident. Operating costs decreased 28%, processing times improved dramatically, and customer satisfaction among approved applicants remained high.

No media investigation occurred. No whistleblowers emerged. Legal risk remained theoretical.

**Financial Impact (9 months)**: +$1.1M

**However**:

In late September, the Consumer Financial Protection Bureau announced new AI lending guidance requiring monthly disparate impact audits and public reporting starting in 2026. Liberty Regional will need to either:
1. Implement expensive monitoring systems ($400K+ annually)
2. Retrain the model with fairness constraints (3-4 months of reduced performance)
3. Face the consequences the board deferred

Additionally, three competitors announced "Fair AI Lending" programs with community partnerships, positioning Liberty Regional as behind the curve on responsible AI.

**The Real Cost**: Liberty Regional got short-term gains but now faces the same decision with less optionality and worse positioning.

**Your Reflection Assignment**:
Does a good outcome justify a risky decision? How should boards think about decisions that "worked out" despite being ethically questionable?

---

**Scenario 1C: "Catastrophic Failure" (15% probability)**

**What Happened - Month 2**:

A software bug in LendSmart™ went undetected during deployment. The bug caused the system to incorrectly calculate debt-to-income ratios for applications with multiple income sources (common among small business owners and gig workers).

For two weeks, the system auto-approved 47 high-risk loans that should have been flagged for review. Total exposure: $8.3M in loans with estimated default rate of 35-40%.

Simultaneously, the system auto-declined 89 well-qualified applicants due to the same bug.

**Compounding Factors**:
- The auto-declined applicants were disproportionately minority applicants (76%)
- One of the incorrectly approved loans was to a business later discovered to be a money laundering front
- Loan officers had flagged concerns about the system but were told to "trust the AI"

**Financial Impact (9 months)**:
- Projected loan defaults: $2.9M
- Legal costs (discrimination + negligence): $1.2M
- Regulatory penalties: $3.5M
- Lost business: $1.8M
- Stock price decline: -31%
- **Net impact**: -$9.4M

**Additional Consequences**:
- Federal investigation into bank's AI governance practices
- CEO forced to resign
- Two board members declined to stand for re-election
- Liberty Regional required to suspend all AI deployments pending review
- Bank became case study in AI risk management failures
- Credit rating downgraded

**The Lesson**: The board deployed a system without adequate testing, monitoring, or human oversight. The efficiency gains weren't worth the existential risk.

**Your Reflection Assignment**:
This is the worst-case scenario. What guardrails could have prevented this? How should boards govern AI systems they don't fully understand?

---

### If Board Votes: Option 2 (Deploy with Fairness Constraints)

**Scenario 2A: "Responsible Innovation Works" (65% probability)**

**What Happened - Months 1-4**:

Liberty Regional worked with FinTech Solutions Inc. to retrain LendSmart™ with fairness constraints. The process took 3.5 months (slightly longer than projected).

The retrained model achieved:
- Reduced disparate impact: Auto-decline rates now within 3 percentage points across demographic groups
- Maintained 85% of efficiency gains (processing time down from 14 days to 7 days)
- Slightly higher false positive rate (approving risky loans) but within acceptable tolerance

**What Happened - Months 5-9**:

Deployment went smoothly. Liberty Regional implemented monthly audits and published quarterly fairness reports (first regional bank to do so).

**Financial Impact (9 months)**:
- Efficiency gains (reduced): +$850K
- Retraining costs: -$180K
- Audit/monitoring costs: -$120K
- **Net impact**: +$550K

**Additional Consequences**:
- Positive media coverage: "Community Bank Shows How to Do AI Right"
- Attracted socially-conscious depositors
- Used as case study in banking industry conferences
- Minimal employee turnover
- Enhanced reputation with regulators
- Stock price up 4%

**The Trade-Off**:
Liberty Regional made less money in Year 1 than Option 1 would have promised, but positioned itself for sustainable, ethical AI adoption. When new regulations came in 2026, Liberty was already compliant.

**Your Reflection Assignment**:
This outcome suggests "doing it right" pays off. But what if the board had faced real competitive crisis where $850K vs. $1.6M made the difference? Would the ethical choice still be clear?

---

**Scenario 2B: "The Fix Didn't Fix Everything" (30% probability)**

**What Happened - Months 1-4**:

The retraining process took 4 months and cost more than expected ($290K). The retrained model reduced but didn't eliminate disparities:
- Auto-decline rates: 16% for Black applicants vs. 12% for white applicants (better than 23% vs. 12%, but still notable)
- Processing times improved to 8 days (vs. 6 days for unconstrained model)

**What Happened - Months 5-9**:

Deployment proceeded but challenges emerged:
- Community advocates argued that 4 percentage points of disparity was still unacceptable
- Loan officers complained the model was still "too harsh" on relationship-based lending
- Competitors deployed unconstrained AI and marketed faster service
- Minor CFPB inquiry (resolved with documentation of fairness efforts)

**Financial Impact (9 months)**:
- Efficiency gains: +$620K
- Retraining costs: -$290K
- Legal/compliance costs: -$150K
- Lost competitive accounts: -$180K
- **Net impact**: $0K (break-even)

**The Reality Check**:
Liberty Regional did "the right thing" but discovered that fairness in AI is harder than adding a constraint. The bank is better positioned than competitors but hasn't solved the fundamental tension between efficiency and equity.

**Your Reflection Assignment**:
If doing the right thing costs money and doesn't fully solve the problem, is it still the right thing? How should boards handle situations where ethical imperatives and business imperatives genuinely conflict?

---

**Scenario 2C: "Technical Complications" (5% probability)**

**What Happened - Months 1-4**:

During retraining, FinTech Solutions Inc. discovered that achieving meaningful fairness constraints required fundamentally changing the model architecture. This was more complex than anticipated.

After 4 months of work, the vendor reported: "We can give you either 90% of the efficiency gains with remaining bias, or 60% of the gains with better fairness. We cannot achieve both with current data and technology."

**What Happened Next**:

The board faced a new decision:
- Accept compromise model (60% of gains, better fairness)
- Revert to Option 1 (deploy original model)
- Shift to Option 4 (delay further for more extensive fixes)
- Choose Option 5 (abandon AI approach)

**Financial Impact (4 months)**:
- Retraining costs spent: -$290K
- No benefits realized yet
- Opportunity costs mounting

**The Lesson**: Technical constraints sometimes override good intentions. The board chose the ethically responsible path but discovered the technology wasn't mature enough to deliver on the promise.

**Your Reflection Assignment**:
When should boards say "this technology isn't ready" vs. "we need to work harder to make it fair"? What responsibility do vendors have when their products can't deliver on fairness promises?

---

### If Board Votes: Option 3 (Deploy + Community Investment)

**Scenario 3A: "Differentiation Through Responsibility" (55% probability)**

**What Happened - Months 1-3**:

Liberty Regional deployed LendSmart™ (original model) while simultaneously launching the "Building Business Together" financial literacy and credit building program in Hartford's underserved communities.

The program included:
- Free business planning workshops
- One-on-one credit counseling
- Micro-loan program for credit-building ($5K-$25K)
- Transparency sessions explaining how AI lending works

**What Happened - Months 4-9**:

The dual approach generated unexpected results:
- **Efficiency gains**: Operating costs down 24% (slightly less than projected due to program costs)
- **Community response**: Initially skeptical, but 127 small business owners participated in workshops
- **Media narrative**: Positioned as "bank that's honest about AI limitations and invests in solutions"
- **Loan quality**: 23 workshop participants successfully obtained loans after improving credit/applications
- **Monitoring**: Monthly audits showed disparities persisted but were transparent and tracked

**Financial Impact (9 months)**:
- Efficiency gains: +$980K
- Community program costs: -$500K
- Increased small business loan volume: +$340K
- **Net impact**: +$820K

**Additional Consequences**:
- Won Hartford Chamber of Commerce "Community Impact Award"
- Featured in American Banker as innovative approach
- Two larger banks inquired about licensing the program model
- Improved employee morale (loan officers involved in program)
- Enhanced brand differentiation from national competitors
- Stock price up 6%

**The Innovation**: Liberty Regional didn't pretend the AI was perfect. Instead, it deployed imperfect technology while investing in making the humans (applicants) more successful with it.

**Your Reflection Assignment**:
This suggests a "both/and" approach can work better than "either/or." But what if the community program had failed to gain trust? Would transparency about AI bias have backfired?

---

**Scenario 3B: "Mixed Signals" (35% probability)**

**What Happened - Months 1-9**:

The deployment and program launch went as planned, but community reception was mixed.

**Successes**:
- Financial literacy workshops well-attended (127 participants)
- AI efficiency gains realized (+$980K)
- Some positive media coverage

**Challenges**:
- Community activists criticized program as "PR stunt" that doesn't address underlying algorithmic bias
- Hartford Courant published opinion piece: "Bank Teaches Applicants How to Pass Biased AI Test"
- Some workshop participants still denied loans after improving credit, leading to frustration
- Loan officers complained of increased workload managing both AI system and program
- Monitoring revealed disparities weren't improving despite program

**Financial Impact (9 months)**:
- Efficiency gains: +$980K
- Program costs: -$500K
- Minor legal/compliance costs: -$90K
- **Net impact**: +$390K

**Reputational Impact**: Mixed. Some see Liberty as leader in responsible AI; others see it as sophisticated reputation laundering.

**The Reality**: Good intentions don't automatically generate good outcomes. Community trust can't be purchased with a $500K program if the underlying technology continues to disadvantage people.

**Your Reflection Assignment**:
When is community investment genuine partnership vs. ethical window-dressing? How should companies handle accusations that they're using philanthropy to excuse harmful technology?

---

**Scenario 3C: "Program Success Reveals System Failure" (10% probability)**

**What Happened - Months 1-9**:

The community program exceeded expectations. Over 200 business owners participated, and 47 successfully improved their credit profiles and business plans through the workshops.

However, when these 47 improved applicants reapplied for loans:
- LendSmart™ still auto-declined 26 of them (55% rate)
- Human loan officer review approved 19 of the 26 on appeal
- Clear evidence emerged that the AI was systematically undervaluing improvements that workshops taught

**The Revelation**: The program accidentally created a controlled experiment proving the AI was biased against exactly the type of applicants the bank was trying to help.

**What Happened Next**:
- Community program director (Liberty employee) blew whistle internally
- Legal counsel advised suspending LendSmart™ deployment
- Media praised the bank's program but questioned why AI was needed if humans had to override it 73% of the time
- Bank faced decision to continue with program alone or fully redesign AI approach

**Financial Impact (9 months)**:
- Efficiency gains: +$980K (but at risk of reversal)
- Program costs: -$500K
- Crisis management: -$200K
- **Net impact**: +$280K (unstable)

**The Irony**: The bank's ethical investment exposed the unethical technology. Now Liberty must decide whether to prioritize the program or the AI.

**Your Reflection Assignment**:
This scenario shows how transparency and genuine community engagement can reveal uncomfortable truths. Should Liberty Regional have known this before deployment? What's the right response now?

---

### If Board Votes: Option 4 (Delay 6 Months)

**Scenario 4A: "Patience Pays Off" (70% probability)**

**What Happened - Months 1-6**:

Liberty Regional hired an independent AI ethics consulting firm to audit both LendSmart™ and the bank's own historical lending patterns.

**Audit Findings**:
- LendSmart™ disparate impact was real but actually BETTER than Liberty's human loan officers over past 5 years
- Human loan officers had 28% decline rate for Black applicants vs. 14% for white applicants (worse than AI's 23% vs. 12%)
- However, AI and human bias were different: Humans showed inconsistency; AI showed systemic patterns

**Recommended Solution**:
- Deploy hybrid model: AI for initial screening, humans for all yellow/red flags
- Retrain AI with fairness constraints AND train humans on implicit bias
- Implement robust monitoring for both AI and human decisions

**What Happened - Months 7-9**:

Liberty deployed the hybrid model with comprehensive training and monitoring.

**Financial Impact (9 months)**:
- Lost opportunity (6 months): -$600K
- Audit costs: -$180K
- Enhanced AI + training: -$220K
- Efficiency gains (3 months): +$350K
- **Net impact**: -$650K Year 1

**Additional Consequences**:
- System performing well with minimal disparities
- Positioned for sustainable long-term gains
- Industry recognition for thorough approach
- Used as case study in banking conferences
- Strong employee buy-in due to inclusive process
- Stock price initially flat, then up 3% on positive reports

**The Long Game**: Liberty sacrificed Year 1 profits for Years 2-10 competitive advantage. By Year 2, cumulative gains will surpass what Option 1 would have delivered.

**Your Reflection Assignment**:
This validates the cautious approach. But what if Liberty's competitors had captured significant market share during the 6-month delay? Would the ethical approach still be "worth it" if it meant business failure?

---

**Scenario 4B: "Audit Reveals Deeper Problems" (20% probability)**

**What Happened - Months 1-6**:

The independent audit revealed troubling findings about BOTH AI and human lending:

**AI Issues**:
- Training data from 2008-2023 included recession period when discrimination was severe
- Model had learned to discriminate in complex, non-obvious ways
- Fixing would require complete model rebuild (8-12 months, $600K+)

**Human Issues**:
- Loan officers showed significant implicit bias in subjective assessments
- No standardized criteria for "relationship lending" decisions
- Inconsistent application of bank policies

**Audit Recommendation**: "Liberty Regional Bank has a lending fairness problem that predates AI. Deploying AI without fixing underlying issues will simply automate discrimination. We recommend 12-month comprehensive remediation."

**Board's New Decision**:
- Extend delay to 12 months (painful but necessary)
- Abandon AI approach entirely and fix human process
- Deploy AI despite audit warnings
- Sell to larger bank that can absorb these issues

**Financial Impact (6 months)**:
- Lost opportunity: -$600K
- Audit costs: -$180K
- Crisis management: -$150K
- **Net impact**: -$930K

**The Crisis**: The board chose caution and discovered problems it didn't want to find. Now facing harder choices with worse options.

**Your Reflection Assignment**:
Sometimes looking closely at a problem reveals it's worse than you thought. Should Liberty have stayed ignorant and deployed AI? What responsibility do boards have to uncover uncomfortable truths?

---

**Scenario 4C: "Delay Creates Opportunity" (10% probability)**

**What Happened - Months 1-6**:

During the delay, two major developments occurred:

**Development 1**: New federal AI lending regulations were announced (taking effect in 2026) that would have required major modifications to LendSmart™ as-is. Liberty's delay meant avoiding costly retrofitting.

**Development 2**: A new AI vendor entered the market with a next-generation fair lending AI that significantly outperformed FinTech Solutions' LendSmart™ on both efficiency AND fairness.

**What Liberty Gained**:
- Avoided obsolete technology investment
- Access to better AI solution
- Regulatory compliance head start
- Reputation as thoughtful adopter

**Financial Impact (9 months)**:
- Lost opportunity: -$600K
- Audit costs: -$180K
- New system deployment (3 months): +$520K
- **Net impact**: -$260K Year 1

**Long-term Positioning**: By Year 2, Liberty is ahead of all competitors who deployed inferior technology.

**The Luck Factor**: This scenario shows how delay can create optionality. The board didn't know new regulations or better tech were coming, but by waiting, they benefited.

**Your Reflection Assignment**:
This is the "lucky delay" scenario. But should boards rely on luck? How do you distinguish strategic patience from procrastination?

---

### If Board Votes: Option 5 (Reject AI, Invest in Human Training)

**Scenario 5A: "Human Touch Wins" (40% probability)**

**What Happened - Months 1-9**:

Liberty Regional invested $300K in comprehensive loan officer training focused on:
- Implicit bias awareness and mitigation
- Standardized evaluation criteria
- Technology tools to assist (not replace) human judgment
- Community relationship building

Additionally, Liberty marketed itself as "The Bank That Knows Your Name" - explicitly positioning against AI-driven competitors.

**Results**:
- Loan processing time improved from 14 to 11 days (better, but not as good as AI)
- Loan officer satisfaction and retention increased
- Quality of lending decisions improved (lower default rates)
- Customer satisfaction highest in bank's history (4.8/5.0)
- Attracted customers who explicitly didn't want "algorithm banking"

**Financial Impact (9 months)**:
- Training costs: -$300K
- Improved retention (reduced turnover costs): +$180K
- Premium customer acquisition: +$220K
- Operational costs unchanged: $0
- **Net impact**: +$100K

**Market Positioning**:
- Differentiated from both megabanks and fintech competitors
- Attracted segment of customers willing to pay for personalized service
- Strong employee morale became recruiting advantage
- Featured in business media as "counter-trend success"

**The Surprise**: Liberty Regional turned rejection of AI into competitive advantage by leaning into what AI can't do—build genuine relationships.

**Your Reflection Assignment**:
This suggests AI isn't always the answer. But is this scalable? Can Liberty compete long-term without technology adoption? Or did it find a sustainable niche?

---

**Scenario 5B: "Falling Behind" (50% probability)**

**What Happened - Months 1-9**:

The training investment improved loan officer performance, but Liberty couldn't overcome fundamental competitive disadvantages:

**Challenges**:
- Processing times (11 days) still far behind AI competitors (6 days)
- Operating costs 22% higher than AI-using peers
- Younger customers (under 40) preferred digital-first competitors
- Lost 8 large commercial clients to faster-moving banks
- Difficulty attracting tech-savvy talent who wanted to work with modern tools

**Financial Impact (9 months)**:
- Training costs: -$300K
- Lost business: -$680K
- Operational efficiency gap: -$420K
- **Net impact**: -$1.4M

**Market Position Deterioration**:
- Market share declined from 4th to 5th in region
- Stock price down 9%
- Activist investors questioning board's technology strategy
- CFO privately advocating for AI adoption

**The Reality Check**: Good intentions and human touch couldn't overcome efficiency gap in competitive market.

**Your Reflection Assignment**:
If rejecting AI means business decline, was it the "ethical" choice? What responsibility does a board have to shareholders and employees when ethical choices threaten the organization's survival?

---

**Scenario 5C: "Vindication Through Competitor Failure" (10% probability)**

**What Happened - Months 1-9**:

Liberty Regional invested in human training and avoided AI. Meanwhile, three of its four major regional competitors rushed to deploy AI lending systems.

**What Happened to Competitors**:
- **Competitor A**: Deployed AI, faced discrimination lawsuit, settled for $4.2M
- **Competitor B**: Deployed AI, discovered major bugs, suspended system after losses
- **Competitor C**: Deployed AI successfully but faced employee walkouts over job displacement
- **Competitor D**: Delayed deployment (similar to Liberty's Option 4 strategy)

**Media Narrative**: "Why Liberty Regional Bank's Human Approach Looks Smart After Competitors' AI Disasters"

**Liberty's Results**:
- Customer acquisition from competitors' scandals
- Recruited top loan officers from competitors cutting staff
- Positioned as "safe, stable, trustworthy" choice
- Increased market share from 4th to 3rd
- Stock price up 12%

**Financial Impact (9 months)**:
- Training costs: -$300K
- Competitive crisis acquisition: +$890K
- Market share gains: +$540K
- **Net impact**: +$1.13M

**The Irony**: Liberty made less profit than AI would have delivered, but more than it expected because competitors' AI adoption failed spectacularly.

**Your Reflection Assignment**:
This is the "we got lucky because they screwed up" scenario. But should boards make decisions based on hoping competitors fail? What if competitors had succeeded?

---

## Instructor Notes: Selecting Consequences

### Decision Framework

**Base selection on**:
1. **Majority vote**: Which option won?
2. **Vote distribution**: Landslide vs. close decision
3. **Quality of deliberation**: Did students grapple with trade-offs?
4. **Pedagogical goals**: What do students most need to learn?

**Probability weights are guidelines**, not rules. Instructor discretion is appropriate.

### Recommended Approaches

**If vote was unanimous or landslide (13+ votes for one option)**:
- Consider revealing a scenario that challenges their confidence
- Use lower-probability outcomes to show uncertainty
- Goal: Teach humility about decision-making under uncertainty

**If vote was close (9-8 or 10-7)**:
- Consider revealing a mixed outcome
- Acknowledge that reasonable people disagreed
- Goal: Reinforce that these are genuinely hard choices

**If deliberation was sophisticated**:
- Reward with realistic "success" scenario
- But include complications to maintain learning
- Goal: Show that good process increases odds but doesn't guarantee outcomes

**If deliberation was superficial**:
- Consider revealing a challenging scenario
- Use consequences to surface issues they didn't discuss
- Goal: Motivate deeper thinking in future cases

### Customization Options

Feel free to modify scenarios or create hybrids based on:
- Specific arguments students made
- Issues they overlooked
- Time available for debrief
- Connection to upcoming course content

### Revealing Consequences

**Recommended reveal format**:

1. **Thank students** for their engagement
2. **Acknowledge** this was a difficult decision with no perfect answer
3. **Reveal** the vote distribution
4. **Present** the consequence scenario
5. **Give 5 minutes** for individual reflection
6. **Discuss** what happened and what they'd do differently
7. **Connect** to broader themes in AI ethics

**Key message**: "Outcomes don't retroactively make decisions right or wrong. We assess decision quality by the information available and reasoning used at the time. But we learn from consequences."

---

## Post-Consequence Reflection Assignment (Blackboard)

**Short assignment** (due before Session 2):

1. Summarize what happened to Liberty Regional based on the board's decision (100 words)
2. Would you change your vote knowing the outcome? Why or why not? (150 words)
3. What did this teach you about AI governance that wasn't clear from the case alone? (150 words)

**Grading**: Simple completion credit (5 points) - goal is reflection, not assessment

---

*These scenarios are designed to be realistic while supporting the pedagogical goals of the course. No outcome is "punishment" for a "wrong" vote - all are learning opportunities.*
